{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eb1fe5d-eccd-44e1-ab53-528756d29b22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import sys\n",
    "import os\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "sys.path.append(os.path.join(os.getcwd(), 'data'))\n",
    "\n",
    "from data_split import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52bfe806-c4cd-4f66-a068-8e430eeee5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义BERT模型用于处理文本信息\n",
    "class BERTModel(nn.Module):\n",
    "    def __init__(self, embed_size, hidden_size, num_layers, num_heads, vocab_size=30522, dropout=0.1, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.positional_encoding = nn.Parameter(torch.randn(1, 512, embed_size))  \n",
    "        self.encoder_layers = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_size,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_size,\n",
    "            dropout=dropout,\n",
    "            batch_first=True  \n",
    "        )\n",
    "        \n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            self.encoder_layers,\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        self.fc = nn.Linear(embed_size, num_classes)\n",
    "\n",
    "    def forward(self, x, attention_mask):\n",
    "        emb = self.embedding(x) + self.positional_encoding[:, :x.size(1), :]\n",
    "        attention_mask = attention_mask.bool()\n",
    "        output = self.encoder(emb, src_key_padding_mask=attention_mask)\n",
    "        cls_token_output = output[:, 0, :]  \n",
    "        logits = self.fc(cls_token_output)  \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ed5345-edcd-4eb2-a8df-2cbe3d1caedc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 定义AlexNet模型用于处理图像信息\n",
    "class AlexNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(AlexNetModel, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "253a55a2-279d-43de-8fb6-9c70aca87ea1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 多模态模型\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, text_model, img_model, fusion_dim = 6, num_classes = 3):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        self.text_model = text_model\n",
    "        self.img_model = img_model\n",
    "        self.fc_fusion = nn.Linear(fusion_dim, num_classes)\n",
    "\n",
    "    def forward(self, img, text, attention_mask):\n",
    "        img_features = self.img_model(img)  \n",
    "        img_features = img_features.view(img_features.size(0), -1)  \n",
    "        \n",
    "        text_features = self.text_model(text, attention_mask)\n",
    "        \n",
    "        combined_features = torch.cat([img_features, text_features], dim=-1)\n",
    "        \n",
    "        output = self.fc_fusion(combined_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce24c6c4-2fcb-4019-b950-05e24c0cce87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#消融实验：仅使用图像信息\n",
    "class ImageModel(nn.Module):\n",
    "    def __init__(self, text_model, img_model, fusion_dim=3, num_classes=3):\n",
    "        super(ImageModel, self).__init__()\n",
    "        self.text_model = text_model\n",
    "        self.img_model = img_model\n",
    "        self.fc_fusion = nn.Linear(fusion_dim, num_classes)  \n",
    "\n",
    "    def forward(self, img, text, attention_mask):\n",
    "        img_features = self.img_model(img)  \n",
    "        img_features = img_features.view(img_features.size(0), -1)  \n",
    "        \n",
    "        output = self.fc_fusion(img_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6be263d4-3c17-4c82-a5df-721ed55f28f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#消融实验：仅使用文本信息\n",
    "class TextModel(nn.Module):\n",
    "    def __init__(self, text_model, img_model, fusion_dim=3, num_classes=3):\n",
    "        super(TextModel, self).__init__()\n",
    "        self.text_model = text_model\n",
    "        self.img_model = img_model\n",
    "        self.fc_fusion = nn.Linear(fusion_dim, num_classes)\n",
    "        \n",
    "    def forward(self, img, text, attention_mask):\n",
    "        text_features = self.text_model(text, attention_mask)\n",
    "\n",
    "        output = self.fc_fusion(text_features)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "526007c3-d046-4537-bcbd-3f02efd536a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 准备数据集\n",
    "train_loader, val_loader, test_loader = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eebd373-dfbe-4515-8ac1-8fe6ecd30b78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 设置训练参数\n",
    "args = {\n",
    "    'lr': 1e-5,                # 学习率\n",
    "    'batch_size': 64,          # 批量大小\n",
    "    'epochs': 20,              # 训练轮次\n",
    "    'embed_size': 256,         # 嵌入维度\n",
    "    'hidden_size': 64,         # 隐藏层维度\n",
    "    'num_layers': 2,           # Transformer 层数\n",
    "    'num_heads': 4,            # Attention heads 数量\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df0c7297-d4d1-4d19-be09-21d0030ea64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU: NVIDIA RTX A4000\n"
     ]
    }
   ],
   "source": [
    "# 检查是否有可用的 GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"CUDA is available. Using GPU: {torch.cuda.get_device_name(0)}\")  # 打印当前使用的 GPU 名称\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2149e4d-01aa-4578-96cf-873799c29892",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text model initialized successfully.\n",
      "Image model initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# 分别初始化BERT模型和ALEXNET模型\n",
    "text_model = BERTModel(vocab_size=30522, embed_size=args['embed_size'], hidden_size=args['hidden_size'], num_layers=args['num_layers'], num_heads=args['num_heads'])\n",
    "print(\"Text model initialized successfully.\")\n",
    "\n",
    "img_model = AlexNetModel(num_classes=3)\n",
    "print(\"Image model initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf0744b0-985e-49a7-8798-d97ddf4df93f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized successfully.\n"
     ]
    }
   ],
   "source": [
    "# 多模态模型初始化\n",
    "model = MultiModalModel(text_model=text_model, img_model=img_model).to(device)\n",
    "only_text_model = TextModel(text_model=text_model, img_model=img_model).to(device)\n",
    "only_image_model = ImageModel(text_model=text_model, img_model=img_model).to(device)\n",
    "print(\"Models initialized successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dfb5fde-6cc4-4f23-a434-088aa7f9203e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加权损失函数\n",
    "class_counts = [1910, 954, 336]  # 训练集中的每个类别的样本数量\n",
    "total_samples = sum(class_counts) \n",
    "class_weights = [total_samples / count for count in class_counts]\n",
    "class_weights = torch.tensor(class_weights).float().to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = Adam(model.parameters(), lr=args['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1099802d-68ce-4ad4-945d-0c020dc5edb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/20...\n",
      "Epoch 1/20, Batch 10/100: Loss: 1.0732\n",
      "Epoch 1/20, Batch 20/100: Loss: 1.1234\n",
      "Epoch 1/20, Batch 30/100: Loss: 1.0794\n",
      "Epoch 1/20, Batch 40/100: Loss: 1.1009\n",
      "Epoch 1/20, Batch 50/100: Loss: 1.1363\n",
      "Epoch 1/20, Batch 60/100: Loss: 1.1204\n",
      "Epoch 1/20, Batch 70/100: Loss: 1.0947\n",
      "Epoch 1/20, Batch 80/100: Loss: 1.1254\n",
      "Epoch 1/20, Batch 90/100: Loss: 1.0848\n",
      "Epoch 1/20, Batch 100/100: Loss: 1.0696\n",
      "Epoch 1/20 - Average Training Loss: 1.1060\n",
      "Epoch 1/20 - Training F1-score: 0.3486\n",
      "Epoch 1/20 - Training Precision: 0.4679\n",
      "Epoch 1/20 - Training Recall: 0.3294\n",
      "Epoch 1/20 - Validation Loss: 1.0957\n",
      "Epoch 1/20 - Validation F1-score: 0.1850\n",
      "Epoch 1/20 - Validation Precision: 0.5024\n",
      "Epoch 1/20 - Validation Recall: 0.3162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved best model with validation F1-score: 0.1850\n",
      "Starting Epoch 2/20...\n",
      "Epoch 2/20, Batch 10/100: Loss: 1.1230\n",
      "Epoch 2/20, Batch 20/100: Loss: 1.1331\n",
      "Epoch 2/20, Batch 30/100: Loss: 1.0940\n",
      "Epoch 2/20, Batch 40/100: Loss: 1.0842\n",
      "Epoch 2/20, Batch 50/100: Loss: 1.0714\n",
      "Epoch 2/20, Batch 60/100: Loss: 1.1064\n",
      "Epoch 2/20, Batch 70/100: Loss: 1.0796\n",
      "Epoch 2/20, Batch 80/100: Loss: 1.0824\n",
      "Epoch 2/20, Batch 90/100: Loss: 1.0820\n",
      "Epoch 2/20, Batch 100/100: Loss: 1.0655\n",
      "Epoch 2/20 - Average Training Loss: 1.0997\n",
      "Epoch 2/20 - Training F1-score: 0.4128\n",
      "Epoch 2/20 - Training Precision: 0.4810\n",
      "Epoch 2/20 - Training Recall: 0.3900\n",
      "Epoch 2/20 - Validation Loss: 1.0946\n",
      "Epoch 2/20 - Validation F1-score: 0.5038\n",
      "Epoch 2/20 - Validation Precision: 0.5211\n",
      "Epoch 2/20 - Validation Recall: 0.5913\n",
      "Saved best model with validation F1-score: 0.5038\n",
      "Starting Epoch 3/20...\n",
      "Epoch 3/20, Batch 10/100: Loss: 1.0821\n",
      "Epoch 3/20, Batch 20/100: Loss: 1.0981\n",
      "Epoch 3/20, Batch 30/100: Loss: 1.0974\n",
      "Epoch 3/20, Batch 40/100: Loss: 1.0859\n",
      "Epoch 3/20, Batch 50/100: Loss: 1.1059\n",
      "Epoch 3/20, Batch 60/100: Loss: 1.1227\n",
      "Epoch 3/20, Batch 70/100: Loss: 1.1044\n",
      "Epoch 3/20, Batch 80/100: Loss: 1.0790\n",
      "Epoch 3/20, Batch 90/100: Loss: 1.1054\n",
      "Epoch 3/20, Batch 100/100: Loss: 1.1084\n",
      "Epoch 3/20 - Average Training Loss: 1.0981\n",
      "Epoch 3/20 - Training F1-score: 0.4836\n",
      "Epoch 3/20 - Training Precision: 0.5002\n",
      "Epoch 3/20 - Training Recall: 0.4703\n",
      "Epoch 3/20 - Validation Loss: 1.0903\n",
      "Epoch 3/20 - Validation F1-score: 0.4670\n",
      "Epoch 3/20 - Validation Precision: 0.5118\n",
      "Epoch 3/20 - Validation Recall: 0.4412\n",
      "Starting Epoch 4/20...\n",
      "Epoch 4/20, Batch 10/100: Loss: 1.0685\n",
      "Epoch 4/20, Batch 20/100: Loss: 1.0801\n",
      "Epoch 4/20, Batch 30/100: Loss: 1.0646\n",
      "Epoch 4/20, Batch 40/100: Loss: 1.1088\n",
      "Epoch 4/20, Batch 50/100: Loss: 1.0864\n",
      "Epoch 4/20, Batch 60/100: Loss: 1.0947\n",
      "Epoch 4/20, Batch 70/100: Loss: 1.1651\n",
      "Epoch 4/20, Batch 80/100: Loss: 1.1033\n",
      "Epoch 4/20, Batch 90/100: Loss: 1.1012\n",
      "Epoch 4/20, Batch 100/100: Loss: 1.1236\n",
      "Epoch 4/20 - Average Training Loss: 1.0932\n",
      "Epoch 4/20 - Training F1-score: 0.4869\n",
      "Epoch 4/20 - Training Precision: 0.5118\n",
      "Epoch 4/20 - Training Recall: 0.4731\n",
      "Epoch 4/20 - Validation Loss: 1.0884\n",
      "Epoch 4/20 - Validation F1-score: 0.4530\n",
      "Epoch 4/20 - Validation Precision: 0.5205\n",
      "Epoch 4/20 - Validation Recall: 0.4213\n",
      "Starting Epoch 5/20...\n",
      "Epoch 5/20, Batch 10/100: Loss: 1.0709\n",
      "Epoch 5/20, Batch 20/100: Loss: 1.1001\n",
      "Epoch 5/20, Batch 30/100: Loss: 1.0096\n",
      "Epoch 5/20, Batch 40/100: Loss: 1.1197\n",
      "Epoch 5/20, Batch 50/100: Loss: 1.0275\n",
      "Epoch 5/20, Batch 60/100: Loss: 1.1009\n",
      "Epoch 5/20, Batch 70/100: Loss: 1.0237\n",
      "Epoch 5/20, Batch 80/100: Loss: 1.1631\n",
      "Epoch 5/20, Batch 90/100: Loss: 1.1146\n",
      "Epoch 5/20, Batch 100/100: Loss: 1.0842\n",
      "Epoch 5/20 - Average Training Loss: 1.0826\n",
      "Epoch 5/20 - Training F1-score: 0.4978\n",
      "Epoch 5/20 - Training Precision: 0.5294\n",
      "Epoch 5/20 - Training Recall: 0.4813\n",
      "Epoch 5/20 - Validation Loss: 1.0863\n",
      "Epoch 5/20 - Validation F1-score: 0.4298\n",
      "Epoch 5/20 - Validation Precision: 0.5471\n",
      "Epoch 5/20 - Validation Recall: 0.3987\n",
      "Starting Epoch 6/20...\n",
      "Epoch 6/20, Batch 10/100: Loss: 1.0905\n",
      "Epoch 6/20, Batch 20/100: Loss: 1.0534\n",
      "Epoch 6/20, Batch 30/100: Loss: 1.0782\n",
      "Epoch 6/20, Batch 40/100: Loss: 1.0378\n",
      "Epoch 6/20, Batch 50/100: Loss: 1.1299\n",
      "Epoch 6/20, Batch 60/100: Loss: 1.0617\n",
      "Epoch 6/20, Batch 70/100: Loss: 1.0756\n",
      "Epoch 6/20, Batch 80/100: Loss: 1.0583\n",
      "Epoch 6/20, Batch 90/100: Loss: 1.0348\n",
      "Epoch 6/20, Batch 100/100: Loss: 1.0874\n",
      "Epoch 6/20 - Average Training Loss: 1.0857\n",
      "Epoch 6/20 - Training F1-score: 0.4477\n",
      "Epoch 6/20 - Training Precision: 0.5328\n",
      "Epoch 6/20 - Training Recall: 0.4128\n",
      "Epoch 6/20 - Validation Loss: 1.0845\n",
      "Epoch 6/20 - Validation F1-score: 0.5285\n",
      "Epoch 6/20 - Validation Precision: 0.5151\n",
      "Epoch 6/20 - Validation Recall: 0.5463\n",
      "Saved best model with validation F1-score: 0.5285\n",
      "Starting Epoch 7/20...\n",
      "Epoch 7/20, Batch 10/100: Loss: 1.0291\n",
      "Epoch 7/20, Batch 20/100: Loss: 1.0487\n",
      "Epoch 7/20, Batch 30/100: Loss: 1.0385\n",
      "Epoch 7/20, Batch 40/100: Loss: 1.0855\n",
      "Epoch 7/20, Batch 50/100: Loss: 1.1339\n",
      "Epoch 7/20, Batch 60/100: Loss: 1.0292\n",
      "Epoch 7/20, Batch 70/100: Loss: 1.0591\n",
      "Epoch 7/20, Batch 80/100: Loss: 1.0830\n",
      "Epoch 7/20, Batch 90/100: Loss: 1.0709\n",
      "Epoch 7/20, Batch 100/100: Loss: 1.0728\n",
      "Epoch 7/20 - Average Training Loss: 1.0797\n",
      "Epoch 7/20 - Training F1-score: 0.4898\n",
      "Epoch 7/20 - Training Precision: 0.5299\n",
      "Epoch 7/20 - Training Recall: 0.4681\n",
      "Epoch 7/20 - Validation Loss: 1.0912\n",
      "Epoch 7/20 - Validation F1-score: 0.3100\n",
      "Epoch 7/20 - Validation Precision: 0.5392\n",
      "Epoch 7/20 - Validation Recall: 0.2913\n",
      "Starting Epoch 8/20...\n",
      "Epoch 8/20, Batch 10/100: Loss: 1.0819\n",
      "Epoch 8/20, Batch 20/100: Loss: 1.0351\n",
      "Epoch 8/20, Batch 30/100: Loss: 1.0876\n",
      "Epoch 8/20, Batch 40/100: Loss: 1.0267\n",
      "Epoch 8/20, Batch 50/100: Loss: 1.0564\n",
      "Epoch 8/20, Batch 60/100: Loss: 1.1026\n",
      "Epoch 8/20, Batch 70/100: Loss: 1.0438\n",
      "Epoch 8/20, Batch 80/100: Loss: 1.0175\n",
      "Epoch 8/20, Batch 90/100: Loss: 1.0680\n",
      "Epoch 8/20, Batch 100/100: Loss: 1.0767\n",
      "Epoch 8/20 - Average Training Loss: 1.0698\n",
      "Epoch 8/20 - Training F1-score: 0.4670\n",
      "Epoch 8/20 - Training Precision: 0.5398\n",
      "Epoch 8/20 - Training Recall: 0.4428\n",
      "Epoch 8/20 - Validation Loss: 1.0923\n",
      "Epoch 8/20 - Validation F1-score: 0.3706\n",
      "Epoch 8/20 - Validation Precision: 0.5341\n",
      "Epoch 8/20 - Validation Recall: 0.3262\n",
      "Starting Epoch 9/20...\n",
      "Epoch 9/20, Batch 10/100: Loss: 1.0807\n",
      "Epoch 9/20, Batch 20/100: Loss: 1.0219\n",
      "Epoch 9/20, Batch 30/100: Loss: 1.0658\n",
      "Epoch 9/20, Batch 40/100: Loss: 1.1034\n",
      "Epoch 9/20, Batch 50/100: Loss: 1.0701\n",
      "Epoch 9/20, Batch 60/100: Loss: 1.0549\n",
      "Epoch 9/20, Batch 70/100: Loss: 1.0460\n",
      "Epoch 9/20, Batch 80/100: Loss: 1.0651\n",
      "Epoch 9/20, Batch 90/100: Loss: 1.0754\n",
      "Epoch 9/20, Batch 100/100: Loss: 1.0663\n",
      "Epoch 9/20 - Average Training Loss: 1.0712\n",
      "Epoch 9/20 - Training F1-score: 0.4747\n",
      "Epoch 9/20 - Training Precision: 0.5417\n",
      "Epoch 9/20 - Training Recall: 0.4466\n",
      "Epoch 9/20 - Validation Loss: 1.0776\n",
      "Epoch 9/20 - Validation F1-score: 0.5082\n",
      "Epoch 9/20 - Validation Precision: 0.5284\n",
      "Epoch 9/20 - Validation Recall: 0.4938\n",
      "Starting Epoch 10/20...\n",
      "Epoch 10/20, Batch 10/100: Loss: 1.1730\n",
      "Epoch 10/20, Batch 20/100: Loss: 0.9962\n",
      "Epoch 10/20, Batch 30/100: Loss: 0.9920\n",
      "Epoch 10/20, Batch 40/100: Loss: 1.0468\n",
      "Epoch 10/20, Batch 50/100: Loss: 1.0258\n",
      "Epoch 10/20, Batch 60/100: Loss: 1.1128\n",
      "Epoch 10/20, Batch 70/100: Loss: 1.0070\n",
      "Epoch 10/20, Batch 80/100: Loss: 1.0306\n",
      "Epoch 10/20, Batch 90/100: Loss: 0.9895\n",
      "Epoch 10/20, Batch 100/100: Loss: 1.1327\n",
      "Epoch 10/20 - Average Training Loss: 1.0657\n",
      "Epoch 10/20 - Training F1-score: 0.4703\n",
      "Epoch 10/20 - Training Precision: 0.5339\n",
      "Epoch 10/20 - Training Recall: 0.4422\n",
      "Epoch 10/20 - Validation Loss: 1.0746\n",
      "Epoch 10/20 - Validation F1-score: 0.4285\n",
      "Epoch 10/20 - Validation Precision: 0.5579\n",
      "Epoch 10/20 - Validation Recall: 0.4163\n",
      "Starting Epoch 11/20...\n",
      "Epoch 11/20, Batch 10/100: Loss: 0.9994\n",
      "Epoch 11/20, Batch 20/100: Loss: 1.0288\n",
      "Epoch 11/20, Batch 30/100: Loss: 1.0275\n",
      "Epoch 11/20, Batch 40/100: Loss: 1.0954\n",
      "Epoch 11/20, Batch 50/100: Loss: 1.0858\n",
      "Epoch 11/20, Batch 60/100: Loss: 1.1491\n",
      "Epoch 11/20, Batch 70/100: Loss: 1.0643\n",
      "Epoch 11/20, Batch 80/100: Loss: 1.1579\n",
      "Epoch 11/20, Batch 90/100: Loss: 1.0916\n",
      "Epoch 11/20, Batch 100/100: Loss: 1.1469\n",
      "Epoch 11/20 - Average Training Loss: 1.0583\n",
      "Epoch 11/20 - Training F1-score: 0.4805\n",
      "Epoch 11/20 - Training Precision: 0.5487\n",
      "Epoch 11/20 - Training Recall: 0.4544\n",
      "Epoch 11/20 - Validation Loss: 1.0781\n",
      "Epoch 11/20 - Validation F1-score: 0.4345\n",
      "Epoch 11/20 - Validation Precision: 0.5360\n",
      "Epoch 11/20 - Validation Recall: 0.3962\n",
      "Starting Epoch 12/20...\n",
      "Epoch 12/20, Batch 10/100: Loss: 1.0579\n",
      "Epoch 12/20, Batch 20/100: Loss: 1.0754\n",
      "Epoch 12/20, Batch 30/100: Loss: 1.0467\n",
      "Epoch 12/20, Batch 40/100: Loss: 0.9976\n",
      "Epoch 12/20, Batch 50/100: Loss: 0.9721\n",
      "Epoch 12/20, Batch 60/100: Loss: 1.0555\n",
      "Epoch 12/20, Batch 70/100: Loss: 1.0300\n",
      "Epoch 12/20, Batch 80/100: Loss: 1.1829\n",
      "Epoch 12/20, Batch 90/100: Loss: 1.0473\n",
      "Epoch 12/20, Batch 100/100: Loss: 1.0952\n",
      "Epoch 12/20 - Average Training Loss: 1.0598\n",
      "Epoch 12/20 - Training F1-score: 0.4782\n",
      "Epoch 12/20 - Training Precision: 0.5523\n",
      "Epoch 12/20 - Training Recall: 0.4478\n",
      "Epoch 12/20 - Validation Loss: 1.0666\n",
      "Epoch 12/20 - Validation F1-score: 0.4882\n",
      "Epoch 12/20 - Validation Precision: 0.5535\n",
      "Epoch 12/20 - Validation Recall: 0.4675\n",
      "Starting Epoch 13/20...\n",
      "Epoch 13/20, Batch 10/100: Loss: 0.9400\n",
      "Epoch 13/20, Batch 20/100: Loss: 1.1161\n",
      "Epoch 13/20, Batch 30/100: Loss: 1.0142\n",
      "Epoch 13/20, Batch 40/100: Loss: 1.0120\n",
      "Epoch 13/20, Batch 50/100: Loss: 1.0819\n",
      "Epoch 13/20, Batch 60/100: Loss: 1.0552\n",
      "Epoch 13/20, Batch 70/100: Loss: 0.9832\n",
      "Epoch 13/20, Batch 80/100: Loss: 1.1059\n",
      "Epoch 13/20, Batch 90/100: Loss: 1.0078\n",
      "Epoch 13/20, Batch 100/100: Loss: 1.0080\n",
      "Epoch 13/20 - Average Training Loss: 1.0500\n",
      "Epoch 13/20 - Training F1-score: 0.4854\n",
      "Epoch 13/20 - Training Precision: 0.5485\n",
      "Epoch 13/20 - Training Recall: 0.4587\n",
      "Epoch 13/20 - Validation Loss: 1.0816\n",
      "Epoch 13/20 - Validation F1-score: 0.3798\n",
      "Epoch 13/20 - Validation Precision: 0.5384\n",
      "Epoch 13/20 - Validation Recall: 0.3588\n",
      "Starting Epoch 14/20...\n",
      "Epoch 14/20, Batch 10/100: Loss: 1.0593\n",
      "Epoch 14/20, Batch 20/100: Loss: 1.0542\n",
      "Epoch 14/20, Batch 30/100: Loss: 1.0281\n",
      "Epoch 14/20, Batch 40/100: Loss: 1.2638\n",
      "Epoch 14/20, Batch 50/100: Loss: 0.9954\n",
      "Epoch 14/20, Batch 60/100: Loss: 1.0071\n",
      "Epoch 14/20, Batch 70/100: Loss: 1.0901\n",
      "Epoch 14/20, Batch 80/100: Loss: 1.1328\n",
      "Epoch 14/20, Batch 90/100: Loss: 1.0230\n",
      "Epoch 14/20, Batch 100/100: Loss: 1.2995\n",
      "Epoch 14/20 - Average Training Loss: 1.0472\n",
      "Epoch 14/20 - Training F1-score: 0.4667\n",
      "Epoch 14/20 - Training Precision: 0.5424\n",
      "Epoch 14/20 - Training Recall: 0.4403\n",
      "Epoch 14/20 - Validation Loss: 1.0761\n",
      "Epoch 14/20 - Validation F1-score: 0.5230\n",
      "Epoch 14/20 - Validation Precision: 0.5420\n",
      "Epoch 14/20 - Validation Recall: 0.5100\n",
      "Starting Epoch 15/20...\n",
      "Epoch 15/20, Batch 10/100: Loss: 1.0111\n",
      "Epoch 15/20, Batch 20/100: Loss: 1.0662\n",
      "Epoch 15/20, Batch 30/100: Loss: 1.0007\n",
      "Epoch 15/20, Batch 40/100: Loss: 1.0505\n",
      "Epoch 15/20, Batch 50/100: Loss: 1.0522\n",
      "Epoch 15/20, Batch 60/100: Loss: 1.0497\n",
      "Epoch 15/20, Batch 70/100: Loss: 0.9604\n",
      "Epoch 15/20, Batch 80/100: Loss: 0.9914\n",
      "Epoch 15/20, Batch 90/100: Loss: 1.0512\n",
      "Epoch 15/20, Batch 100/100: Loss: 1.0663\n",
      "Epoch 15/20 - Average Training Loss: 1.0332\n",
      "Epoch 15/20 - Training F1-score: 0.4723\n",
      "Epoch 15/20 - Training Precision: 0.5547\n",
      "Epoch 15/20 - Training Recall: 0.4450\n",
      "Epoch 15/20 - Validation Loss: 1.0697\n",
      "Epoch 15/20 - Validation F1-score: 0.4094\n",
      "Epoch 15/20 - Validation Precision: 0.5564\n",
      "Epoch 15/20 - Validation Recall: 0.3713\n",
      "Starting Epoch 16/20...\n",
      "Epoch 16/20, Batch 10/100: Loss: 1.0538\n",
      "Epoch 16/20, Batch 20/100: Loss: 0.9919\n",
      "Epoch 16/20, Batch 30/100: Loss: 1.0450\n",
      "Epoch 16/20, Batch 40/100: Loss: 1.0294\n",
      "Epoch 16/20, Batch 50/100: Loss: 1.0428\n",
      "Epoch 16/20, Batch 60/100: Loss: 1.0202\n",
      "Epoch 16/20, Batch 70/100: Loss: 1.0393\n",
      "Epoch 16/20, Batch 80/100: Loss: 1.0316\n",
      "Epoch 16/20, Batch 90/100: Loss: 0.8644\n",
      "Epoch 16/20, Batch 100/100: Loss: 0.9291\n",
      "Epoch 16/20 - Average Training Loss: 1.0246\n",
      "Epoch 16/20 - Training F1-score: 0.4895\n",
      "Epoch 16/20 - Training Precision: 0.5590\n",
      "Epoch 16/20 - Training Recall: 0.4653\n",
      "Epoch 16/20 - Validation Loss: 1.0760\n",
      "Epoch 16/20 - Validation F1-score: 0.4720\n",
      "Epoch 16/20 - Validation Precision: 0.5479\n",
      "Epoch 16/20 - Validation Recall: 0.4425\n",
      "Starting Epoch 17/20...\n",
      "Epoch 17/20, Batch 10/100: Loss: 1.0090\n",
      "Epoch 17/20, Batch 20/100: Loss: 0.9564\n",
      "Epoch 17/20, Batch 30/100: Loss: 0.9282\n",
      "Epoch 17/20, Batch 40/100: Loss: 1.0062\n",
      "Epoch 17/20, Batch 50/100: Loss: 1.0762\n",
      "Epoch 17/20, Batch 60/100: Loss: 0.9891\n",
      "Epoch 17/20, Batch 70/100: Loss: 1.0157\n",
      "Epoch 17/20, Batch 80/100: Loss: 0.9357\n",
      "Epoch 17/20, Batch 90/100: Loss: 0.9740\n",
      "Epoch 17/20, Batch 100/100: Loss: 0.8017\n",
      "Epoch 17/20 - Average Training Loss: 1.0201\n",
      "Epoch 17/20 - Training F1-score: 0.4863\n",
      "Epoch 17/20 - Training Precision: 0.5597\n",
      "Epoch 17/20 - Training Recall: 0.4609\n",
      "Epoch 17/20 - Validation Loss: 1.0831\n",
      "Epoch 17/20 - Validation F1-score: 0.4821\n",
      "Epoch 17/20 - Validation Precision: 0.5305\n",
      "Epoch 17/20 - Validation Recall: 0.4575\n",
      "Starting Epoch 18/20...\n",
      "Epoch 18/20, Batch 10/100: Loss: 0.9936\n",
      "Epoch 18/20, Batch 20/100: Loss: 0.9403\n",
      "Epoch 18/20, Batch 30/100: Loss: 1.0873\n",
      "Epoch 18/20, Batch 40/100: Loss: 0.8860\n",
      "Epoch 18/20, Batch 50/100: Loss: 1.0153\n",
      "Epoch 18/20, Batch 60/100: Loss: 0.8926\n",
      "Epoch 18/20, Batch 70/100: Loss: 1.0803\n",
      "Epoch 18/20, Batch 80/100: Loss: 1.0742\n",
      "Epoch 18/20, Batch 90/100: Loss: 0.8910\n",
      "Epoch 18/20, Batch 100/100: Loss: 0.9165\n",
      "Epoch 18/20 - Average Training Loss: 1.0132\n",
      "Epoch 18/20 - Training F1-score: 0.4829\n",
      "Epoch 18/20 - Training Precision: 0.5679\n",
      "Epoch 18/20 - Training Recall: 0.4550\n",
      "Epoch 18/20 - Validation Loss: 1.0739\n",
      "Epoch 18/20 - Validation F1-score: 0.4042\n",
      "Epoch 18/20 - Validation Precision: 0.5604\n",
      "Epoch 18/20 - Validation Recall: 0.3937\n",
      "Starting Epoch 19/20...\n",
      "Epoch 19/20, Batch 10/100: Loss: 1.1479\n",
      "Epoch 19/20, Batch 20/100: Loss: 1.0199\n",
      "Epoch 19/20, Batch 30/100: Loss: 0.9286\n",
      "Epoch 19/20, Batch 40/100: Loss: 1.0586\n",
      "Epoch 19/20, Batch 50/100: Loss: 0.9042\n",
      "Epoch 19/20, Batch 60/100: Loss: 1.0914\n",
      "Epoch 19/20, Batch 70/100: Loss: 0.9515\n",
      "Epoch 19/20, Batch 80/100: Loss: 1.1904\n",
      "Epoch 19/20, Batch 90/100: Loss: 1.1091\n",
      "Epoch 19/20, Batch 100/100: Loss: 1.0691\n",
      "Epoch 19/20 - Average Training Loss: 1.0099\n",
      "Epoch 19/20 - Training F1-score: 0.4801\n",
      "Epoch 19/20 - Training Precision: 0.5683\n",
      "Epoch 19/20 - Training Recall: 0.4553\n",
      "Epoch 19/20 - Validation Loss: 1.0884\n",
      "Epoch 19/20 - Validation F1-score: 0.4131\n",
      "Epoch 19/20 - Validation Precision: 0.5419\n",
      "Epoch 19/20 - Validation Recall: 0.3887\n",
      "Starting Epoch 20/20...\n",
      "Epoch 20/20, Batch 10/100: Loss: 0.9674\n",
      "Epoch 20/20, Batch 20/100: Loss: 0.9167\n",
      "Epoch 20/20, Batch 30/100: Loss: 1.0089\n",
      "Epoch 20/20, Batch 40/100: Loss: 1.0818\n",
      "Epoch 20/20, Batch 50/100: Loss: 0.9771\n",
      "Epoch 20/20, Batch 60/100: Loss: 1.0063\n",
      "Epoch 20/20, Batch 70/100: Loss: 1.0592\n",
      "Epoch 20/20, Batch 80/100: Loss: 1.0108\n",
      "Epoch 20/20, Batch 90/100: Loss: 0.8550\n",
      "Epoch 20/20, Batch 100/100: Loss: 0.8644\n",
      "Epoch 20/20 - Average Training Loss: 0.9813\n",
      "Epoch 20/20 - Training F1-score: 0.4925\n",
      "Epoch 20/20 - Training Precision: 0.5707\n",
      "Epoch 20/20 - Training Recall: 0.4713\n",
      "Epoch 20/20 - Validation Loss: 1.0924\n",
      "Epoch 20/20 - Validation F1-score: 0.4590\n",
      "Epoch 20/20 - Validation Precision: 0.5317\n",
      "Epoch 20/20 - Validation Recall: 0.4263\n"
     ]
    }
   ],
   "source": [
    "# 多模态模型\n",
    "best_val_f1 = 0.0  \n",
    "best_train_f1 = 0.0 \n",
    "\n",
    "for epoch in range(args['epochs']):\n",
    "    print(f\"Starting Epoch {epoch+1}/{args['epochs']}...\")\n",
    "    \n",
    "    # 训练\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        text_inputs, attention_masks, img_inputs, labels = batch\n",
    "        \n",
    "        text_inputs = text_inputs.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        img_inputs = img_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(img_inputs, text_inputs, attention_masks)  \n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{args['epochs']}, Batch {batch_idx+1}/{len(train_loader)}: \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Average Training Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')  # 计算加权的 F1-score\n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training F1-score: {train_f1:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training Precision: {train_precision:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training Recall: {train_recall:.4f}\")\n",
    "    \n",
    "    # 验证\n",
    "    only_text_model.eval()\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            text_inputs, attention_masks, img_inputs, labels = batch\n",
    "            text_inputs = text_inputs.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            img_inputs = img_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(img_inputs, text_inputs, attention_masks) # 使用仅文本模型\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Loss: {val_loss / len(val_loader):.4f}\")\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')  # 计算加权的 F1-score\n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted')\n",
    "        val_recall = recall_score(all_val_labels, all_val_preds, average='weighted')\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation F1-score: {val_f1:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Precision: {val_precision:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Recall: {val_recall:.4f}\")\n",
    "    \n",
    "    # 储存最佳模型\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(model.state_dict(), 'val_best_model.pth')\n",
    "        print(f\"Saved best model with validation F1-score: {best_val_f1:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f75ee9ab-8373-441a-a435-38be34fc7cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15542/3157717887.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('val_best_model.pth'))\n"
     ]
    }
   ],
   "source": [
    "# 加载最佳模型进行测试\n",
    "model.load_state_dict(torch.load('val_best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = []\n",
    "    for batch in test_loader:\n",
    "        text_inputs, attention_masks, img_inputs, _ = batch\n",
    "        text_inputs = text_inputs.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        img_inputs = img_inputs.to(device)\n",
    "\n",
    "        outputs = model(img_inputs, text_inputs, attention_masks)\n",
    "\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.tolist())\n",
    "        \n",
    "with open('val_predictions.txt', 'w') as f:\n",
    "    for pred in predictions:\n",
    "        f.write(str(pred) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80d0917e-10c2-4fe9-bf24-697d80838aec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/20...\n",
      "Epoch 1/20, Batch 10/100: Loss: 1.1764\n",
      "Epoch 1/20, Batch 20/100: Loss: 1.1222\n",
      "Epoch 1/20, Batch 30/100: Loss: 1.1050\n",
      "Epoch 1/20, Batch 40/100: Loss: 1.1192\n",
      "Epoch 1/20, Batch 50/100: Loss: 1.0263\n",
      "Epoch 1/20, Batch 60/100: Loss: 1.0687\n",
      "Epoch 1/20, Batch 70/100: Loss: 1.1469\n",
      "Epoch 1/20, Batch 80/100: Loss: 1.0742\n",
      "Epoch 1/20, Batch 90/100: Loss: 1.1030\n",
      "Epoch 1/20, Batch 100/100: Loss: 1.0788\n",
      "Epoch 1/20 - Average Training Loss: 1.1122\n",
      "Epoch 1/20 - Training F1-score: 0.4619\n",
      "Epoch 1/20 - Training Precision: 0.4430\n",
      "Epoch 1/20 - Training Recall: 0.4988\n",
      "Epoch 1/20 - Validation Loss: 1.0977\n",
      "Epoch 1/20 - Validation F1-score: 0.4470\n",
      "Epoch 1/20 - Validation Precision: 0.3570\n",
      "Epoch 1/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Batch 10/100: Loss: 1.0956\n",
      "Epoch 2/20, Batch 20/100: Loss: 1.0930\n",
      "Epoch 2/20, Batch 30/100: Loss: 1.0686\n",
      "Epoch 2/20, Batch 40/100: Loss: 1.0600\n",
      "Epoch 2/20, Batch 50/100: Loss: 1.0895\n",
      "Epoch 2/20, Batch 60/100: Loss: 1.0730\n",
      "Epoch 2/20, Batch 70/100: Loss: 1.1106\n",
      "Epoch 2/20, Batch 80/100: Loss: 1.0827\n",
      "Epoch 2/20, Batch 90/100: Loss: 1.0694\n",
      "Epoch 2/20, Batch 100/100: Loss: 1.0787\n",
      "Epoch 2/20 - Average Training Loss: 1.0994\n",
      "Epoch 2/20 - Training F1-score: 0.4551\n",
      "Epoch 2/20 - Training Precision: 0.4542\n",
      "Epoch 2/20 - Training Recall: 0.4559\n",
      "Epoch 2/20 - Validation Loss: 1.0977\n",
      "Epoch 2/20 - Validation F1-score: 0.4470\n",
      "Epoch 2/20 - Validation Precision: 0.3570\n",
      "Epoch 2/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Batch 10/100: Loss: 1.1025\n",
      "Epoch 3/20, Batch 20/100: Loss: 1.1096\n",
      "Epoch 3/20, Batch 30/100: Loss: 1.0914\n",
      "Epoch 3/20, Batch 40/100: Loss: 1.1209\n",
      "Epoch 3/20, Batch 50/100: Loss: 1.1091\n",
      "Epoch 3/20, Batch 60/100: Loss: 1.1084\n",
      "Epoch 3/20, Batch 70/100: Loss: 1.1302\n",
      "Epoch 3/20, Batch 80/100: Loss: 1.0910\n",
      "Epoch 3/20, Batch 90/100: Loss: 1.1325\n",
      "Epoch 3/20, Batch 100/100: Loss: 1.0920\n",
      "Epoch 3/20 - Average Training Loss: 1.1001\n",
      "Epoch 3/20 - Training F1-score: 0.4470\n",
      "Epoch 3/20 - Training Precision: 0.4553\n",
      "Epoch 3/20 - Training Recall: 0.4444\n",
      "Epoch 3/20 - Validation Loss: 1.0968\n",
      "Epoch 3/20 - Validation F1-score: 0.1374\n",
      "Epoch 3/20 - Validation Precision: 0.0893\n",
      "Epoch 3/20 - Validation Recall: 0.2988\n",
      "Starting Epoch 4/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Batch 10/100: Loss: 1.0871\n",
      "Epoch 4/20, Batch 20/100: Loss: 1.1005\n",
      "Epoch 4/20, Batch 30/100: Loss: 1.1292\n",
      "Epoch 4/20, Batch 40/100: Loss: 1.1029\n",
      "Epoch 4/20, Batch 50/100: Loss: 1.1242\n",
      "Epoch 4/20, Batch 60/100: Loss: 1.0931\n",
      "Epoch 4/20, Batch 70/100: Loss: 1.0923\n",
      "Epoch 4/20, Batch 80/100: Loss: 1.1100\n",
      "Epoch 4/20, Batch 90/100: Loss: 1.0907\n",
      "Epoch 4/20, Batch 100/100: Loss: 1.0686\n",
      "Epoch 4/20 - Average Training Loss: 1.1016\n",
      "Epoch 4/20 - Training F1-score: 0.4069\n",
      "Epoch 4/20 - Training Precision: 0.4433\n",
      "Epoch 4/20 - Training Recall: 0.3981\n",
      "Epoch 4/20 - Validation Loss: 1.0974\n",
      "Epoch 4/20 - Validation F1-score: 0.4470\n",
      "Epoch 4/20 - Validation Precision: 0.3570\n",
      "Epoch 4/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 5/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Batch 10/100: Loss: 1.1000\n",
      "Epoch 5/20, Batch 20/100: Loss: 1.0962\n",
      "Epoch 5/20, Batch 30/100: Loss: 1.0967\n",
      "Epoch 5/20, Batch 40/100: Loss: 1.0936\n",
      "Epoch 5/20, Batch 50/100: Loss: 1.1018\n",
      "Epoch 5/20, Batch 60/100: Loss: 1.0920\n",
      "Epoch 5/20, Batch 70/100: Loss: 1.0814\n",
      "Epoch 5/20, Batch 80/100: Loss: 1.1109\n",
      "Epoch 5/20, Batch 90/100: Loss: 1.0975\n",
      "Epoch 5/20, Batch 100/100: Loss: 1.1109\n",
      "Epoch 5/20 - Average Training Loss: 1.0985\n",
      "Epoch 5/20 - Training F1-score: 0.4425\n",
      "Epoch 5/20 - Training Precision: 0.4724\n",
      "Epoch 5/20 - Training Recall: 0.4228\n",
      "Epoch 5/20 - Validation Loss: 1.0970\n",
      "Epoch 5/20 - Validation F1-score: 0.1374\n",
      "Epoch 5/20 - Validation Precision: 0.0893\n",
      "Epoch 5/20 - Validation Recall: 0.2988\n",
      "Starting Epoch 6/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Batch 10/100: Loss: 1.0958\n",
      "Epoch 6/20, Batch 20/100: Loss: 1.0985\n",
      "Epoch 6/20, Batch 30/100: Loss: 1.0715\n",
      "Epoch 6/20, Batch 40/100: Loss: 1.0813\n",
      "Epoch 6/20, Batch 50/100: Loss: 1.0985\n",
      "Epoch 6/20, Batch 60/100: Loss: 1.1314\n",
      "Epoch 6/20, Batch 70/100: Loss: 1.0353\n",
      "Epoch 6/20, Batch 80/100: Loss: 1.1344\n",
      "Epoch 6/20, Batch 90/100: Loss: 1.1069\n",
      "Epoch 6/20, Batch 100/100: Loss: 1.1252\n",
      "Epoch 6/20 - Average Training Loss: 1.1013\n",
      "Epoch 6/20 - Training F1-score: 0.4012\n",
      "Epoch 6/20 - Training Precision: 0.4538\n",
      "Epoch 6/20 - Training Recall: 0.3984\n",
      "Epoch 6/20 - Validation Loss: 1.0966\n",
      "Epoch 6/20 - Validation F1-score: 0.1374\n",
      "Epoch 6/20 - Validation Precision: 0.0893\n",
      "Epoch 6/20 - Validation Recall: 0.2988\n",
      "Starting Epoch 7/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Batch 10/100: Loss: 1.1084\n",
      "Epoch 7/20, Batch 20/100: Loss: 1.0900\n",
      "Epoch 7/20, Batch 30/100: Loss: 1.1025\n",
      "Epoch 7/20, Batch 40/100: Loss: 1.1059\n",
      "Epoch 7/20, Batch 50/100: Loss: 1.1326\n",
      "Epoch 7/20, Batch 60/100: Loss: 1.0794\n",
      "Epoch 7/20, Batch 70/100: Loss: 1.1015\n",
      "Epoch 7/20, Batch 80/100: Loss: 1.0846\n",
      "Epoch 7/20, Batch 90/100: Loss: 1.1082\n",
      "Epoch 7/20, Batch 100/100: Loss: 1.1143\n",
      "Epoch 7/20 - Average Training Loss: 1.0985\n",
      "Epoch 7/20 - Training F1-score: 0.4657\n",
      "Epoch 7/20 - Training Precision: 0.4699\n",
      "Epoch 7/20 - Training Recall: 0.4719\n",
      "Epoch 7/20 - Validation Loss: 1.0967\n",
      "Epoch 7/20 - Validation F1-score: 0.4470\n",
      "Epoch 7/20 - Validation Precision: 0.3570\n",
      "Epoch 7/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 8/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Batch 10/100: Loss: 1.1099\n",
      "Epoch 8/20, Batch 20/100: Loss: 1.0940\n",
      "Epoch 8/20, Batch 30/100: Loss: 1.1243\n",
      "Epoch 8/20, Batch 40/100: Loss: 1.1095\n",
      "Epoch 8/20, Batch 50/100: Loss: 1.0832\n",
      "Epoch 8/20, Batch 60/100: Loss: 1.1142\n",
      "Epoch 8/20, Batch 70/100: Loss: 1.0911\n",
      "Epoch 8/20, Batch 80/100: Loss: 1.0848\n",
      "Epoch 8/20, Batch 90/100: Loss: 1.1300\n",
      "Epoch 8/20, Batch 100/100: Loss: 1.0756\n",
      "Epoch 8/20 - Average Training Loss: 1.0998\n",
      "Epoch 8/20 - Training F1-score: 0.4348\n",
      "Epoch 8/20 - Training Precision: 0.4469\n",
      "Epoch 8/20 - Training Recall: 0.4319\n",
      "Epoch 8/20 - Validation Loss: 1.0966\n",
      "Epoch 8/20 - Validation F1-score: 0.4470\n",
      "Epoch 8/20 - Validation Precision: 0.3570\n",
      "Epoch 8/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 9/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Batch 10/100: Loss: 1.1322\n",
      "Epoch 9/20, Batch 20/100: Loss: 1.0904\n",
      "Epoch 9/20, Batch 30/100: Loss: 1.0851\n",
      "Epoch 9/20, Batch 40/100: Loss: 1.1091\n",
      "Epoch 9/20, Batch 50/100: Loss: 1.1020\n",
      "Epoch 9/20, Batch 60/100: Loss: 1.0779\n",
      "Epoch 9/20, Batch 70/100: Loss: 1.1223\n",
      "Epoch 9/20, Batch 80/100: Loss: 1.0653\n",
      "Epoch 9/20, Batch 90/100: Loss: 1.0696\n",
      "Epoch 9/20, Batch 100/100: Loss: 1.0968\n",
      "Epoch 9/20 - Average Training Loss: 1.1002\n",
      "Epoch 9/20 - Training F1-score: 0.4506\n",
      "Epoch 9/20 - Training Precision: 0.4584\n",
      "Epoch 9/20 - Training Recall: 0.4547\n",
      "Epoch 9/20 - Validation Loss: 1.0966\n",
      "Epoch 9/20 - Validation F1-score: 0.4683\n",
      "Epoch 9/20 - Validation Precision: 0.5183\n",
      "Epoch 9/20 - Validation Recall: 0.6012\n",
      "Starting Epoch 10/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Batch 10/100: Loss: 1.0987\n",
      "Epoch 10/20, Batch 20/100: Loss: 1.0824\n",
      "Epoch 10/20, Batch 30/100: Loss: 1.0992\n",
      "Epoch 10/20, Batch 40/100: Loss: 1.0829\n",
      "Epoch 10/20, Batch 50/100: Loss: 1.0922\n",
      "Epoch 10/20, Batch 60/100: Loss: 1.1067\n",
      "Epoch 10/20, Batch 70/100: Loss: 1.0729\n",
      "Epoch 10/20, Batch 80/100: Loss: 1.0916\n",
      "Epoch 10/20, Batch 90/100: Loss: 1.0658\n",
      "Epoch 10/20, Batch 100/100: Loss: 1.0577\n",
      "Epoch 10/20 - Average Training Loss: 1.0978\n",
      "Epoch 10/20 - Training F1-score: 0.4435\n",
      "Epoch 10/20 - Training Precision: 0.4686\n",
      "Epoch 10/20 - Training Recall: 0.4363\n",
      "Epoch 10/20 - Validation Loss: 1.0966\n",
      "Epoch 10/20 - Validation F1-score: 0.4846\n",
      "Epoch 10/20 - Validation Precision: 0.4530\n",
      "Epoch 10/20 - Validation Recall: 0.5525\n",
      "Starting Epoch 11/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Batch 10/100: Loss: 1.0975\n",
      "Epoch 11/20, Batch 20/100: Loss: 1.1027\n",
      "Epoch 11/20, Batch 30/100: Loss: 1.1185\n",
      "Epoch 11/20, Batch 40/100: Loss: 1.1191\n",
      "Epoch 11/20, Batch 50/100: Loss: 1.1005\n",
      "Epoch 11/20, Batch 60/100: Loss: 1.0895\n",
      "Epoch 11/20, Batch 70/100: Loss: 1.1152\n",
      "Epoch 11/20, Batch 80/100: Loss: 1.0993\n",
      "Epoch 11/20, Batch 90/100: Loss: 1.0685\n",
      "Epoch 11/20, Batch 100/100: Loss: 1.1099\n",
      "Epoch 11/20 - Average Training Loss: 1.0977\n",
      "Epoch 11/20 - Training F1-score: 0.4675\n",
      "Epoch 11/20 - Training Precision: 0.4588\n",
      "Epoch 11/20 - Training Recall: 0.4778\n",
      "Epoch 11/20 - Validation Loss: 1.0965\n",
      "Epoch 11/20 - Validation F1-score: 0.4682\n",
      "Epoch 11/20 - Validation Precision: 0.4952\n",
      "Epoch 11/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 12/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Batch 10/100: Loss: 1.1331\n",
      "Epoch 12/20, Batch 20/100: Loss: 1.0960\n",
      "Epoch 12/20, Batch 30/100: Loss: 1.1139\n",
      "Epoch 12/20, Batch 40/100: Loss: 1.1117\n",
      "Epoch 12/20, Batch 50/100: Loss: 1.1054\n",
      "Epoch 12/20, Batch 60/100: Loss: 1.1030\n",
      "Epoch 12/20, Batch 70/100: Loss: 1.0786\n",
      "Epoch 12/20, Batch 80/100: Loss: 1.0961\n",
      "Epoch 12/20, Batch 90/100: Loss: 1.1245\n",
      "Epoch 12/20, Batch 100/100: Loss: 1.1236\n",
      "Epoch 12/20 - Average Training Loss: 1.0983\n",
      "Epoch 12/20 - Training F1-score: 0.4432\n",
      "Epoch 12/20 - Training Precision: 0.4647\n",
      "Epoch 12/20 - Training Recall: 0.4406\n",
      "Epoch 12/20 - Validation Loss: 1.0965\n",
      "Epoch 12/20 - Validation F1-score: 0.4846\n",
      "Epoch 12/20 - Validation Precision: 0.4530\n",
      "Epoch 12/20 - Validation Recall: 0.5525\n",
      "Starting Epoch 13/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Batch 10/100: Loss: 1.1093\n",
      "Epoch 13/20, Batch 20/100: Loss: 1.0945\n",
      "Epoch 13/20, Batch 30/100: Loss: 1.1038\n",
      "Epoch 13/20, Batch 40/100: Loss: 1.0939\n",
      "Epoch 13/20, Batch 50/100: Loss: 1.1045\n",
      "Epoch 13/20, Batch 60/100: Loss: 1.0837\n",
      "Epoch 13/20, Batch 70/100: Loss: 1.0885\n",
      "Epoch 13/20, Batch 80/100: Loss: 1.0858\n",
      "Epoch 13/20, Batch 90/100: Loss: 1.1195\n",
      "Epoch 13/20, Batch 100/100: Loss: 1.1042\n",
      "Epoch 13/20 - Average Training Loss: 1.1012\n",
      "Epoch 13/20 - Training F1-score: 0.4079\n",
      "Epoch 13/20 - Training Precision: 0.4472\n",
      "Epoch 13/20 - Training Recall: 0.3862\n",
      "Epoch 13/20 - Validation Loss: 1.0966\n",
      "Epoch 13/20 - Validation F1-score: 0.1374\n",
      "Epoch 13/20 - Validation Precision: 0.0893\n",
      "Epoch 13/20 - Validation Recall: 0.2988\n",
      "Starting Epoch 14/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Batch 10/100: Loss: 1.0689\n",
      "Epoch 14/20, Batch 20/100: Loss: 1.0797\n",
      "Epoch 14/20, Batch 30/100: Loss: 1.0823\n",
      "Epoch 14/20, Batch 40/100: Loss: 1.1067\n",
      "Epoch 14/20, Batch 50/100: Loss: 1.1026\n",
      "Epoch 14/20, Batch 60/100: Loss: 1.0950\n",
      "Epoch 14/20, Batch 70/100: Loss: 1.0943\n",
      "Epoch 14/20, Batch 80/100: Loss: 1.1094\n",
      "Epoch 14/20, Batch 90/100: Loss: 1.0874\n",
      "Epoch 14/20, Batch 100/100: Loss: 1.1022\n",
      "Epoch 14/20 - Average Training Loss: 1.1004\n",
      "Epoch 14/20 - Training F1-score: 0.4544\n",
      "Epoch 14/20 - Training Precision: 0.4446\n",
      "Epoch 14/20 - Training Recall: 0.4694\n",
      "Epoch 14/20 - Validation Loss: 1.0972\n",
      "Epoch 14/20 - Validation F1-score: 0.4470\n",
      "Epoch 14/20 - Validation Precision: 0.3570\n",
      "Epoch 14/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 15/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Batch 10/100: Loss: 1.1187\n",
      "Epoch 15/20, Batch 20/100: Loss: 1.0976\n",
      "Epoch 15/20, Batch 30/100: Loss: 1.0883\n",
      "Epoch 15/20, Batch 40/100: Loss: 1.1058\n",
      "Epoch 15/20, Batch 50/100: Loss: 1.0829\n",
      "Epoch 15/20, Batch 60/100: Loss: 1.0956\n",
      "Epoch 15/20, Batch 70/100: Loss: 1.0749\n",
      "Epoch 15/20, Batch 80/100: Loss: 1.1150\n",
      "Epoch 15/20, Batch 90/100: Loss: 1.0657\n",
      "Epoch 15/20, Batch 100/100: Loss: 1.1232\n",
      "Epoch 15/20 - Average Training Loss: 1.0983\n",
      "Epoch 15/20 - Training F1-score: 0.4548\n",
      "Epoch 15/20 - Training Precision: 0.4591\n",
      "Epoch 15/20 - Training Recall: 0.4547\n",
      "Epoch 15/20 - Validation Loss: 1.0971\n",
      "Epoch 15/20 - Validation F1-score: 0.1374\n",
      "Epoch 15/20 - Validation Precision: 0.0893\n",
      "Epoch 15/20 - Validation Recall: 0.2988\n",
      "Starting Epoch 16/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Batch 10/100: Loss: 1.0654\n",
      "Epoch 16/20, Batch 20/100: Loss: 1.0909\n",
      "Epoch 16/20, Batch 30/100: Loss: 1.0988\n",
      "Epoch 16/20, Batch 40/100: Loss: 1.1122\n",
      "Epoch 16/20, Batch 50/100: Loss: 1.1006\n",
      "Epoch 16/20, Batch 60/100: Loss: 1.0714\n",
      "Epoch 16/20, Batch 70/100: Loss: 1.1000\n",
      "Epoch 16/20, Batch 80/100: Loss: 1.1045\n",
      "Epoch 16/20, Batch 90/100: Loss: 1.1242\n",
      "Epoch 16/20, Batch 100/100: Loss: 1.1014\n",
      "Epoch 16/20 - Average Training Loss: 1.0996\n",
      "Epoch 16/20 - Training F1-score: 0.4490\n",
      "Epoch 16/20 - Training Precision: 0.4459\n",
      "Epoch 16/20 - Training Recall: 0.4553\n",
      "Epoch 16/20 - Validation Loss: 1.0967\n",
      "Epoch 16/20 - Validation F1-score: 0.4911\n",
      "Epoch 16/20 - Validation Precision: 0.4636\n",
      "Epoch 16/20 - Validation Recall: 0.5225\n",
      "Starting Epoch 17/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Batch 10/100: Loss: 1.1030\n",
      "Epoch 17/20, Batch 20/100: Loss: 1.1093\n",
      "Epoch 17/20, Batch 30/100: Loss: 1.0893\n",
      "Epoch 17/20, Batch 40/100: Loss: 1.1111\n",
      "Epoch 17/20, Batch 50/100: Loss: 1.1373\n",
      "Epoch 17/20, Batch 60/100: Loss: 1.1097\n",
      "Epoch 17/20, Batch 70/100: Loss: 1.1000\n",
      "Epoch 17/20, Batch 80/100: Loss: 1.1150\n",
      "Epoch 17/20, Batch 90/100: Loss: 1.1001\n",
      "Epoch 17/20, Batch 100/100: Loss: 1.0803\n",
      "Epoch 17/20 - Average Training Loss: 1.1003\n",
      "Epoch 17/20 - Training F1-score: 0.4195\n",
      "Epoch 17/20 - Training Precision: 0.4331\n",
      "Epoch 17/20 - Training Recall: 0.4156\n",
      "Epoch 17/20 - Validation Loss: 1.0967\n",
      "Epoch 17/20 - Validation F1-score: 0.4846\n",
      "Epoch 17/20 - Validation Precision: 0.4530\n",
      "Epoch 17/20 - Validation Recall: 0.5525\n",
      "Starting Epoch 18/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Batch 10/100: Loss: 1.1062\n",
      "Epoch 18/20, Batch 20/100: Loss: 1.0873\n",
      "Epoch 18/20, Batch 30/100: Loss: 1.0988\n",
      "Epoch 18/20, Batch 40/100: Loss: 1.0977\n",
      "Epoch 18/20, Batch 50/100: Loss: 1.1393\n",
      "Epoch 18/20, Batch 60/100: Loss: 1.0988\n",
      "Epoch 18/20, Batch 70/100: Loss: 1.1113\n",
      "Epoch 18/20, Batch 80/100: Loss: 1.1267\n",
      "Epoch 18/20, Batch 90/100: Loss: 1.0953\n",
      "Epoch 18/20, Batch 100/100: Loss: 1.1142\n",
      "Epoch 18/20 - Average Training Loss: 1.1020\n",
      "Epoch 18/20 - Training F1-score: 0.4103\n",
      "Epoch 18/20 - Training Precision: 0.4416\n",
      "Epoch 18/20 - Training Recall: 0.3981\n",
      "Epoch 18/20 - Validation Loss: 1.0969\n",
      "Epoch 18/20 - Validation F1-score: 0.4470\n",
      "Epoch 18/20 - Validation Precision: 0.3570\n",
      "Epoch 18/20 - Validation Recall: 0.5975\n",
      "Starting Epoch 19/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Batch 10/100: Loss: 1.1136\n",
      "Epoch 19/20, Batch 20/100: Loss: 1.0654\n",
      "Epoch 19/20, Batch 30/100: Loss: 1.1007\n",
      "Epoch 19/20, Batch 40/100: Loss: 1.0918\n",
      "Epoch 19/20, Batch 50/100: Loss: 1.1090\n",
      "Epoch 19/20, Batch 60/100: Loss: 1.0737\n",
      "Epoch 19/20, Batch 70/100: Loss: 1.0928\n",
      "Epoch 19/20, Batch 80/100: Loss: 1.1117\n",
      "Epoch 19/20, Batch 90/100: Loss: 1.1226\n",
      "Epoch 19/20, Batch 100/100: Loss: 1.1289\n",
      "Epoch 19/20 - Average Training Loss: 1.1009\n",
      "Epoch 19/20 - Training F1-score: 0.4363\n",
      "Epoch 19/20 - Training Precision: 0.4497\n",
      "Epoch 19/20 - Training Recall: 0.4266\n",
      "Epoch 19/20 - Validation Loss: 1.0964\n",
      "Epoch 19/20 - Validation F1-score: 0.1374\n",
      "Epoch 19/20 - Validation Precision: 0.0893\n",
      "Epoch 19/20 - Validation Recall: 0.2988\n",
      "Starting Epoch 20/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Batch 10/100: Loss: 1.0897\n",
      "Epoch 20/20, Batch 20/100: Loss: 1.1347\n",
      "Epoch 20/20, Batch 30/100: Loss: 1.0940\n",
      "Epoch 20/20, Batch 40/100: Loss: 1.1420\n",
      "Epoch 20/20, Batch 50/100: Loss: 1.1012\n",
      "Epoch 20/20, Batch 60/100: Loss: 1.1115\n",
      "Epoch 20/20, Batch 70/100: Loss: 1.1109\n",
      "Epoch 20/20, Batch 80/100: Loss: 1.0850\n",
      "Epoch 20/20, Batch 90/100: Loss: 1.0754\n",
      "Epoch 20/20, Batch 100/100: Loss: 1.0975\n",
      "Epoch 20/20 - Average Training Loss: 1.0973\n",
      "Epoch 20/20 - Training F1-score: 0.4675\n",
      "Epoch 20/20 - Training Precision: 0.4643\n",
      "Epoch 20/20 - Training Recall: 0.4719\n",
      "Epoch 20/20 - Validation Loss: 1.0964\n",
      "Epoch 20/20 - Validation F1-score: 0.1374\n",
      "Epoch 20/20 - Validation Precision: 0.0893\n",
      "Epoch 20/20 - Validation Recall: 0.2988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# 消融实验：只使用文本信息\n",
    "\n",
    "best_val_f1 = 0.0  \n",
    "best_train_f1 = 0.0  \n",
    "\n",
    "for epoch in range(args['epochs']):\n",
    "    print(f\"Starting Epoch {epoch+1}/{args['epochs']}...\")\n",
    "    \n",
    "    # 训练\n",
    "    only_text_model.train()\n",
    "    running_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        text_inputs, attention_masks, img_inputs, labels = batch\n",
    "        \n",
    "        text_inputs = text_inputs.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        img_inputs = img_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = only_text_model(img_inputs, text_inputs, attention_masks)  \n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{args['epochs']}, Batch {batch_idx+1}/{len(train_loader)}: \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Average Training Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')  \n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training F1-score: {train_f1:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training Precision: {train_precision:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training Recall: {train_recall:.4f}\")\n",
    "\n",
    "    # 验证\n",
    "    only_text_model.eval()\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            text_inputs, attention_masks, img_inputs, labels = batch\n",
    "            text_inputs = text_inputs.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            img_inputs = img_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = only_text_model(img_inputs, text_inputs, attention_masks)  \n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Loss: {val_loss / len(val_loader):.4f}\")\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted') \n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted')\n",
    "        val_recall = recall_score(all_val_labels, all_val_preds, average='weighted')\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation F1-score: {val_f1:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Precision: {val_precision:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Recall: {val_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27096c3c-cac7-4da0-8e71-0d7f50323eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1/20...\n",
      "Epoch 1/20, Batch 10/100: Loss: 1.1278\n",
      "Epoch 1/20, Batch 20/100: Loss: 1.1090\n",
      "Epoch 1/20, Batch 30/100: Loss: 1.1091\n",
      "Epoch 1/20, Batch 40/100: Loss: 1.0709\n",
      "Epoch 1/20, Batch 50/100: Loss: 1.1118\n",
      "Epoch 1/20, Batch 60/100: Loss: 1.0884\n",
      "Epoch 1/20, Batch 70/100: Loss: 1.1151\n",
      "Epoch 1/20, Batch 80/100: Loss: 1.0965\n",
      "Epoch 1/20, Batch 90/100: Loss: 1.0649\n",
      "Epoch 1/20, Batch 100/100: Loss: 1.0690\n",
      "Epoch 1/20 - Average Training Loss: 1.1034\n",
      "Epoch 1/20 - Training F1-score: 0.4750\n",
      "Epoch 1/20 - Training Precision: 0.4530\n",
      "Epoch 1/20 - Training Recall: 0.4997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Validation Loss: 1.0993\n",
      "Epoch 1/20 - Validation F1-score: 0.4718\n",
      "Epoch 1/20 - Validation Precision: 0.4512\n",
      "Epoch 1/20 - Validation Recall: 0.4950\n",
      "Starting Epoch 2/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Batch 10/100: Loss: 1.0732\n",
      "Epoch 2/20, Batch 20/100: Loss: 1.1283\n",
      "Epoch 2/20, Batch 30/100: Loss: 1.0652\n",
      "Epoch 2/20, Batch 40/100: Loss: 1.0635\n",
      "Epoch 2/20, Batch 50/100: Loss: 1.1126\n",
      "Epoch 2/20, Batch 60/100: Loss: 1.0760\n",
      "Epoch 2/20, Batch 70/100: Loss: 1.0703\n",
      "Epoch 2/20, Batch 80/100: Loss: 1.0805\n",
      "Epoch 2/20, Batch 90/100: Loss: 1.1170\n",
      "Epoch 2/20, Batch 100/100: Loss: 1.0873\n",
      "Epoch 2/20 - Average Training Loss: 1.0991\n",
      "Epoch 2/20 - Training F1-score: 0.4847\n",
      "Epoch 2/20 - Training Precision: 0.4644\n",
      "Epoch 2/20 - Training Recall: 0.5081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Validation Loss: 1.0956\n",
      "Epoch 2/20 - Validation F1-score: 0.4878\n",
      "Epoch 2/20 - Validation Precision: 0.4689\n",
      "Epoch 2/20 - Validation Recall: 0.5100\n",
      "Starting Epoch 3/20...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Batch 10/100: Loss: 1.0638\n",
      "Epoch 3/20, Batch 20/100: Loss: 1.1139\n",
      "Epoch 3/20, Batch 30/100: Loss: 1.1108\n",
      "Epoch 3/20, Batch 40/100: Loss: 1.0845\n",
      "Epoch 3/20, Batch 50/100: Loss: 1.1123\n",
      "Epoch 3/20, Batch 60/100: Loss: 1.1081\n",
      "Epoch 3/20, Batch 70/100: Loss: 1.0956\n",
      "Epoch 3/20, Batch 80/100: Loss: 1.0750\n",
      "Epoch 3/20, Batch 90/100: Loss: 1.1555\n",
      "Epoch 3/20, Batch 100/100: Loss: 1.0903\n",
      "Epoch 3/20 - Average Training Loss: 1.0982\n",
      "Epoch 3/20 - Training F1-score: 0.4821\n",
      "Epoch 3/20 - Training Precision: 0.4822\n",
      "Epoch 3/20 - Training Recall: 0.5059\n",
      "Epoch 3/20 - Validation Loss: 1.0951\n",
      "Epoch 3/20 - Validation F1-score: 0.4934\n",
      "Epoch 3/20 - Validation Precision: 0.4930\n",
      "Epoch 3/20 - Validation Recall: 0.5400\n",
      "Starting Epoch 4/20...\n",
      "Epoch 4/20, Batch 10/100: Loss: 1.0854\n",
      "Epoch 4/20, Batch 20/100: Loss: 1.1098\n",
      "Epoch 4/20, Batch 30/100: Loss: 1.0771\n",
      "Epoch 4/20, Batch 40/100: Loss: 1.0460\n",
      "Epoch 4/20, Batch 50/100: Loss: 1.0814\n",
      "Epoch 4/20, Batch 60/100: Loss: 1.1067\n",
      "Epoch 4/20, Batch 70/100: Loss: 1.0904\n",
      "Epoch 4/20, Batch 80/100: Loss: 1.1059\n",
      "Epoch 4/20, Batch 90/100: Loss: 1.0933\n",
      "Epoch 4/20, Batch 100/100: Loss: 1.1303\n",
      "Epoch 4/20 - Average Training Loss: 1.0925\n",
      "Epoch 4/20 - Training F1-score: 0.4930\n",
      "Epoch 4/20 - Training Precision: 0.4931\n",
      "Epoch 4/20 - Training Recall: 0.4966\n",
      "Epoch 4/20 - Validation Loss: 1.0929\n",
      "Epoch 4/20 - Validation F1-score: 0.4237\n",
      "Epoch 4/20 - Validation Precision: 0.5071\n",
      "Epoch 4/20 - Validation Recall: 0.4263\n",
      "Starting Epoch 5/20...\n",
      "Epoch 5/20, Batch 10/100: Loss: 1.1305\n",
      "Epoch 5/20, Batch 20/100: Loss: 1.1001\n",
      "Epoch 5/20, Batch 30/100: Loss: 1.0968\n",
      "Epoch 5/20, Batch 40/100: Loss: 1.0641\n",
      "Epoch 5/20, Batch 50/100: Loss: 1.1756\n",
      "Epoch 5/20, Batch 60/100: Loss: 1.1220\n",
      "Epoch 5/20, Batch 70/100: Loss: 1.0393\n",
      "Epoch 5/20, Batch 80/100: Loss: 1.1178\n",
      "Epoch 5/20, Batch 90/100: Loss: 1.0871\n",
      "Epoch 5/20, Batch 100/100: Loss: 1.0686\n",
      "Epoch 5/20 - Average Training Loss: 1.0904\n",
      "Epoch 5/20 - Training F1-score: 0.4921\n",
      "Epoch 5/20 - Training Precision: 0.5016\n",
      "Epoch 5/20 - Training Recall: 0.4853\n",
      "Epoch 5/20 - Validation Loss: 1.0884\n",
      "Epoch 5/20 - Validation F1-score: 0.4877\n",
      "Epoch 5/20 - Validation Precision: 0.4902\n",
      "Epoch 5/20 - Validation Recall: 0.4863\n",
      "Starting Epoch 6/20...\n",
      "Epoch 6/20, Batch 10/100: Loss: 1.0679\n",
      "Epoch 6/20, Batch 20/100: Loss: 1.1130\n",
      "Epoch 6/20, Batch 30/100: Loss: 1.0549\n",
      "Epoch 6/20, Batch 40/100: Loss: 1.0254\n",
      "Epoch 6/20, Batch 50/100: Loss: 1.1038\n",
      "Epoch 6/20, Batch 60/100: Loss: 1.1029\n",
      "Epoch 6/20, Batch 70/100: Loss: 1.1139\n",
      "Epoch 6/20, Batch 80/100: Loss: 1.1063\n",
      "Epoch 6/20, Batch 90/100: Loss: 1.1057\n",
      "Epoch 6/20, Batch 100/100: Loss: 1.1017\n",
      "Epoch 6/20 - Average Training Loss: 1.0885\n",
      "Epoch 6/20 - Training F1-score: 0.4898\n",
      "Epoch 6/20 - Training Precision: 0.5070\n",
      "Epoch 6/20 - Training Recall: 0.4772\n",
      "Epoch 6/20 - Validation Loss: 1.0890\n",
      "Epoch 6/20 - Validation F1-score: 0.5181\n",
      "Epoch 6/20 - Validation Precision: 0.5104\n",
      "Epoch 6/20 - Validation Recall: 0.5387\n",
      "Starting Epoch 7/20...\n",
      "Epoch 7/20, Batch 10/100: Loss: 1.1058\n",
      "Epoch 7/20, Batch 20/100: Loss: 1.0245\n",
      "Epoch 7/20, Batch 30/100: Loss: 1.1709\n",
      "Epoch 7/20, Batch 40/100: Loss: 1.0482\n",
      "Epoch 7/20, Batch 50/100: Loss: 1.0436\n",
      "Epoch 7/20, Batch 60/100: Loss: 1.1087\n",
      "Epoch 7/20, Batch 70/100: Loss: 1.1214\n",
      "Epoch 7/20, Batch 80/100: Loss: 1.1109\n",
      "Epoch 7/20, Batch 90/100: Loss: 1.0991\n",
      "Epoch 7/20, Batch 100/100: Loss: 1.0318\n",
      "Epoch 7/20 - Average Training Loss: 1.0839\n",
      "Epoch 7/20 - Training F1-score: 0.5055\n",
      "Epoch 7/20 - Training Precision: 0.5118\n",
      "Epoch 7/20 - Training Recall: 0.5000\n",
      "Epoch 7/20 - Validation Loss: 1.0890\n",
      "Epoch 7/20 - Validation F1-score: 0.4684\n",
      "Epoch 7/20 - Validation Precision: 0.5056\n",
      "Epoch 7/20 - Validation Recall: 0.4825\n",
      "Starting Epoch 8/20...\n",
      "Epoch 8/20, Batch 10/100: Loss: 1.0628\n",
      "Epoch 8/20, Batch 20/100: Loss: 0.9826\n",
      "Epoch 8/20, Batch 30/100: Loss: 1.0673\n",
      "Epoch 8/20, Batch 40/100: Loss: 1.1211\n",
      "Epoch 8/20, Batch 50/100: Loss: 1.1633\n",
      "Epoch 8/20, Batch 60/100: Loss: 1.0836\n",
      "Epoch 8/20, Batch 70/100: Loss: 1.0760\n",
      "Epoch 8/20, Batch 80/100: Loss: 1.0218\n",
      "Epoch 8/20, Batch 90/100: Loss: 1.0643\n",
      "Epoch 8/20, Batch 100/100: Loss: 1.0205\n",
      "Epoch 8/20 - Average Training Loss: 1.0803\n",
      "Epoch 8/20 - Training F1-score: 0.4926\n",
      "Epoch 8/20 - Training Precision: 0.5119\n",
      "Epoch 8/20 - Training Recall: 0.4791\n",
      "Epoch 8/20 - Validation Loss: 1.0844\n",
      "Epoch 8/20 - Validation F1-score: 0.4749\n",
      "Epoch 8/20 - Validation Precision: 0.5057\n",
      "Epoch 8/20 - Validation Recall: 0.4575\n",
      "Starting Epoch 9/20...\n",
      "Epoch 9/20, Batch 10/100: Loss: 1.0374\n",
      "Epoch 9/20, Batch 20/100: Loss: 1.1751\n",
      "Epoch 9/20, Batch 30/100: Loss: 1.0673\n",
      "Epoch 9/20, Batch 40/100: Loss: 1.0681\n",
      "Epoch 9/20, Batch 50/100: Loss: 1.0860\n",
      "Epoch 9/20, Batch 60/100: Loss: 1.1106\n",
      "Epoch 9/20, Batch 70/100: Loss: 1.0902\n",
      "Epoch 9/20, Batch 80/100: Loss: 1.0636\n",
      "Epoch 9/20, Batch 90/100: Loss: 1.0747\n",
      "Epoch 9/20, Batch 100/100: Loss: 1.0349\n",
      "Epoch 9/20 - Average Training Loss: 1.0771\n",
      "Epoch 9/20 - Training F1-score: 0.4976\n",
      "Epoch 9/20 - Training Precision: 0.5184\n",
      "Epoch 9/20 - Training Recall: 0.4853\n",
      "Epoch 9/20 - Validation Loss: 1.0863\n",
      "Epoch 9/20 - Validation F1-score: 0.4927\n",
      "Epoch 9/20 - Validation Precision: 0.4989\n",
      "Epoch 9/20 - Validation Recall: 0.4875\n",
      "Starting Epoch 10/20...\n",
      "Epoch 10/20, Batch 10/100: Loss: 1.1123\n",
      "Epoch 10/20, Batch 20/100: Loss: 1.1179\n",
      "Epoch 10/20, Batch 30/100: Loss: 1.0984\n",
      "Epoch 10/20, Batch 40/100: Loss: 1.0967\n",
      "Epoch 10/20, Batch 50/100: Loss: 1.1601\n",
      "Epoch 10/20, Batch 60/100: Loss: 1.1218\n",
      "Epoch 10/20, Batch 70/100: Loss: 1.0128\n",
      "Epoch 10/20, Batch 80/100: Loss: 1.0734\n",
      "Epoch 10/20, Batch 90/100: Loss: 1.0571\n",
      "Epoch 10/20, Batch 100/100: Loss: 1.1569\n",
      "Epoch 10/20 - Average Training Loss: 1.0761\n",
      "Epoch 10/20 - Training F1-score: 0.5076\n",
      "Epoch 10/20 - Training Precision: 0.5279\n",
      "Epoch 10/20 - Training Recall: 0.4931\n",
      "Epoch 10/20 - Validation Loss: 1.0867\n",
      "Epoch 10/20 - Validation F1-score: 0.4540\n",
      "Epoch 10/20 - Validation Precision: 0.5181\n",
      "Epoch 10/20 - Validation Recall: 0.4338\n",
      "Starting Epoch 11/20...\n",
      "Epoch 11/20, Batch 10/100: Loss: 1.1409\n",
      "Epoch 11/20, Batch 20/100: Loss: 1.0815\n",
      "Epoch 11/20, Batch 30/100: Loss: 1.0728\n",
      "Epoch 11/20, Batch 40/100: Loss: 1.1370\n",
      "Epoch 11/20, Batch 50/100: Loss: 1.0796\n",
      "Epoch 11/20, Batch 60/100: Loss: 1.0818\n",
      "Epoch 11/20, Batch 70/100: Loss: 1.0694\n",
      "Epoch 11/20, Batch 80/100: Loss: 1.0074\n",
      "Epoch 11/20, Batch 90/100: Loss: 1.0702\n",
      "Epoch 11/20, Batch 100/100: Loss: 1.0990\n",
      "Epoch 11/20 - Average Training Loss: 1.0692\n",
      "Epoch 11/20 - Training F1-score: 0.5033\n",
      "Epoch 11/20 - Training Precision: 0.5280\n",
      "Epoch 11/20 - Training Recall: 0.4875\n",
      "Epoch 11/20 - Validation Loss: 1.0848\n",
      "Epoch 11/20 - Validation F1-score: 0.4805\n",
      "Epoch 11/20 - Validation Precision: 0.5148\n",
      "Epoch 11/20 - Validation Recall: 0.4650\n",
      "Starting Epoch 12/20...\n",
      "Epoch 12/20, Batch 10/100: Loss: 1.0704\n",
      "Epoch 12/20, Batch 20/100: Loss: 1.0861\n",
      "Epoch 12/20, Batch 30/100: Loss: 1.0664\n",
      "Epoch 12/20, Batch 40/100: Loss: 1.0569\n",
      "Epoch 12/20, Batch 50/100: Loss: 1.0315\n",
      "Epoch 12/20, Batch 60/100: Loss: 1.0707\n",
      "Epoch 12/20, Batch 70/100: Loss: 1.1183\n",
      "Epoch 12/20, Batch 80/100: Loss: 1.1022\n",
      "Epoch 12/20, Batch 90/100: Loss: 1.0507\n",
      "Epoch 12/20, Batch 100/100: Loss: 1.0501\n",
      "Epoch 12/20 - Average Training Loss: 1.0686\n",
      "Epoch 12/20 - Training F1-score: 0.5066\n",
      "Epoch 12/20 - Training Precision: 0.5246\n",
      "Epoch 12/20 - Training Recall: 0.4944\n",
      "Epoch 12/20 - Validation Loss: 1.0884\n",
      "Epoch 12/20 - Validation F1-score: 0.4571\n",
      "Epoch 12/20 - Validation Precision: 0.5219\n",
      "Epoch 12/20 - Validation Recall: 0.4363\n",
      "Starting Epoch 13/20...\n",
      "Epoch 13/20, Batch 10/100: Loss: 1.0514\n",
      "Epoch 13/20, Batch 20/100: Loss: 1.0482\n",
      "Epoch 13/20, Batch 30/100: Loss: 1.0271\n",
      "Epoch 13/20, Batch 40/100: Loss: 0.9317\n",
      "Epoch 13/20, Batch 50/100: Loss: 1.0981\n",
      "Epoch 13/20, Batch 60/100: Loss: 0.9977\n",
      "Epoch 13/20, Batch 70/100: Loss: 1.1811\n",
      "Epoch 13/20, Batch 80/100: Loss: 1.0993\n",
      "Epoch 13/20, Batch 90/100: Loss: 1.1228\n",
      "Epoch 13/20, Batch 100/100: Loss: 1.0973\n",
      "Epoch 13/20 - Average Training Loss: 1.0648\n",
      "Epoch 13/20 - Training F1-score: 0.5064\n",
      "Epoch 13/20 - Training Precision: 0.5319\n",
      "Epoch 13/20 - Training Recall: 0.4913\n",
      "Epoch 13/20 - Validation Loss: 1.0879\n",
      "Epoch 13/20 - Validation F1-score: 0.4489\n",
      "Epoch 13/20 - Validation Precision: 0.5292\n",
      "Epoch 13/20 - Validation Recall: 0.4188\n",
      "Starting Epoch 14/20...\n",
      "Epoch 14/20, Batch 10/100: Loss: 0.9723\n",
      "Epoch 14/20, Batch 20/100: Loss: 1.1267\n",
      "Epoch 14/20, Batch 30/100: Loss: 0.9551\n",
      "Epoch 14/20, Batch 40/100: Loss: 1.1038\n",
      "Epoch 14/20, Batch 50/100: Loss: 1.0274\n",
      "Epoch 14/20, Batch 60/100: Loss: 1.1271\n",
      "Epoch 14/20, Batch 70/100: Loss: 1.0305\n",
      "Epoch 14/20, Batch 80/100: Loss: 1.0228\n",
      "Epoch 14/20, Batch 90/100: Loss: 1.0874\n",
      "Epoch 14/20, Batch 100/100: Loss: 0.9135\n",
      "Epoch 14/20 - Average Training Loss: 1.0539\n",
      "Epoch 14/20 - Training F1-score: 0.5192\n",
      "Epoch 14/20 - Training Precision: 0.5488\n",
      "Epoch 14/20 - Training Recall: 0.5016\n",
      "Epoch 14/20 - Validation Loss: 1.0777\n",
      "Epoch 14/20 - Validation F1-score: 0.5044\n",
      "Epoch 14/20 - Validation Precision: 0.5207\n",
      "Epoch 14/20 - Validation Recall: 0.5100\n",
      "Starting Epoch 15/20...\n",
      "Epoch 15/20, Batch 10/100: Loss: 1.1687\n",
      "Epoch 15/20, Batch 20/100: Loss: 1.0079\n",
      "Epoch 15/20, Batch 30/100: Loss: 0.9835\n",
      "Epoch 15/20, Batch 40/100: Loss: 1.0801\n",
      "Epoch 15/20, Batch 50/100: Loss: 1.0671\n",
      "Epoch 15/20, Batch 60/100: Loss: 1.0303\n",
      "Epoch 15/20, Batch 70/100: Loss: 1.1132\n",
      "Epoch 15/20, Batch 80/100: Loss: 0.8856\n",
      "Epoch 15/20, Batch 90/100: Loss: 0.9191\n",
      "Epoch 15/20, Batch 100/100: Loss: 0.8917\n",
      "Epoch 15/20 - Average Training Loss: 1.0474\n",
      "Epoch 15/20 - Training F1-score: 0.5214\n",
      "Epoch 15/20 - Training Precision: 0.5573\n",
      "Epoch 15/20 - Training Recall: 0.5022\n",
      "Epoch 15/20 - Validation Loss: 1.0892\n",
      "Epoch 15/20 - Validation F1-score: 0.5113\n",
      "Epoch 15/20 - Validation Precision: 0.5061\n",
      "Epoch 15/20 - Validation Recall: 0.5188\n",
      "Starting Epoch 16/20...\n",
      "Epoch 16/20, Batch 10/100: Loss: 0.9812\n",
      "Epoch 16/20, Batch 20/100: Loss: 1.0741\n",
      "Epoch 16/20, Batch 30/100: Loss: 1.0922\n",
      "Epoch 16/20, Batch 40/100: Loss: 1.0562\n",
      "Epoch 16/20, Batch 50/100: Loss: 1.0625\n",
      "Epoch 16/20, Batch 60/100: Loss: 0.9386\n",
      "Epoch 16/20, Batch 70/100: Loss: 1.0044\n",
      "Epoch 16/20, Batch 80/100: Loss: 1.0759\n",
      "Epoch 16/20, Batch 90/100: Loss: 1.0123\n",
      "Epoch 16/20, Batch 100/100: Loss: 1.0357\n",
      "Epoch 16/20 - Average Training Loss: 1.0450\n",
      "Epoch 16/20 - Training F1-score: 0.5203\n",
      "Epoch 16/20 - Training Precision: 0.5500\n",
      "Epoch 16/20 - Training Recall: 0.5019\n",
      "Epoch 16/20 - Validation Loss: 1.0708\n",
      "Epoch 16/20 - Validation F1-score: 0.4440\n",
      "Epoch 16/20 - Validation Precision: 0.5354\n",
      "Epoch 16/20 - Validation Recall: 0.4200\n",
      "Starting Epoch 17/20...\n",
      "Epoch 17/20, Batch 10/100: Loss: 1.1464\n",
      "Epoch 17/20, Batch 20/100: Loss: 1.0838\n",
      "Epoch 17/20, Batch 30/100: Loss: 0.8820\n",
      "Epoch 17/20, Batch 40/100: Loss: 1.0530\n",
      "Epoch 17/20, Batch 50/100: Loss: 1.0212\n",
      "Epoch 17/20, Batch 60/100: Loss: 1.0181\n",
      "Epoch 17/20, Batch 70/100: Loss: 1.0801\n",
      "Epoch 17/20, Batch 80/100: Loss: 1.1501\n",
      "Epoch 17/20, Batch 90/100: Loss: 0.9674\n",
      "Epoch 17/20, Batch 100/100: Loss: 1.0747\n",
      "Epoch 17/20 - Average Training Loss: 1.0346\n",
      "Epoch 17/20 - Training F1-score: 0.5134\n",
      "Epoch 17/20 - Training Precision: 0.5487\n",
      "Epoch 17/20 - Training Recall: 0.4944\n",
      "Epoch 17/20 - Validation Loss: 1.0715\n",
      "Epoch 17/20 - Validation F1-score: 0.4671\n",
      "Epoch 17/20 - Validation Precision: 0.5359\n",
      "Epoch 17/20 - Validation Recall: 0.4450\n",
      "Starting Epoch 18/20...\n",
      "Epoch 18/20, Batch 10/100: Loss: 1.0419\n",
      "Epoch 18/20, Batch 20/100: Loss: 1.0112\n",
      "Epoch 18/20, Batch 30/100: Loss: 0.9876\n",
      "Epoch 18/20, Batch 40/100: Loss: 1.0673\n",
      "Epoch 18/20, Batch 50/100: Loss: 1.0305\n",
      "Epoch 18/20, Batch 60/100: Loss: 0.9112\n",
      "Epoch 18/20, Batch 70/100: Loss: 0.9756\n",
      "Epoch 18/20, Batch 80/100: Loss: 1.0500\n",
      "Epoch 18/20, Batch 90/100: Loss: 0.9738\n",
      "Epoch 18/20, Batch 100/100: Loss: 1.0653\n",
      "Epoch 18/20 - Average Training Loss: 1.0358\n",
      "Epoch 18/20 - Training F1-score: 0.5355\n",
      "Epoch 18/20 - Training Precision: 0.5663\n",
      "Epoch 18/20 - Training Recall: 0.5184\n",
      "Epoch 18/20 - Validation Loss: 1.0788\n",
      "Epoch 18/20 - Validation F1-score: 0.4817\n",
      "Epoch 18/20 - Validation Precision: 0.5367\n",
      "Epoch 18/20 - Validation Recall: 0.4562\n",
      "Starting Epoch 19/20...\n",
      "Epoch 19/20, Batch 10/100: Loss: 0.8423\n",
      "Epoch 19/20, Batch 20/100: Loss: 0.9679\n",
      "Epoch 19/20, Batch 30/100: Loss: 1.1304\n",
      "Epoch 19/20, Batch 40/100: Loss: 1.1043\n",
      "Epoch 19/20, Batch 50/100: Loss: 0.9431\n",
      "Epoch 19/20, Batch 60/100: Loss: 1.0875\n",
      "Epoch 19/20, Batch 70/100: Loss: 0.9485\n",
      "Epoch 19/20, Batch 80/100: Loss: 0.9363\n",
      "Epoch 19/20, Batch 90/100: Loss: 1.0400\n",
      "Epoch 19/20, Batch 100/100: Loss: 1.0526\n",
      "Epoch 19/20 - Average Training Loss: 1.0230\n",
      "Epoch 19/20 - Training F1-score: 0.5313\n",
      "Epoch 19/20 - Training Precision: 0.5723\n",
      "Epoch 19/20 - Training Recall: 0.5109\n",
      "Epoch 19/20 - Validation Loss: 1.0714\n",
      "Epoch 19/20 - Validation F1-score: 0.5013\n",
      "Epoch 19/20 - Validation Precision: 0.5329\n",
      "Epoch 19/20 - Validation Recall: 0.4825\n",
      "Starting Epoch 20/20...\n",
      "Epoch 20/20, Batch 10/100: Loss: 1.1355\n",
      "Epoch 20/20, Batch 20/100: Loss: 1.1605\n",
      "Epoch 20/20, Batch 30/100: Loss: 1.2360\n",
      "Epoch 20/20, Batch 40/100: Loss: 0.9939\n",
      "Epoch 20/20, Batch 50/100: Loss: 0.9241\n",
      "Epoch 20/20, Batch 60/100: Loss: 1.0978\n",
      "Epoch 20/20, Batch 70/100: Loss: 0.9864\n",
      "Epoch 20/20, Batch 80/100: Loss: 1.0635\n",
      "Epoch 20/20, Batch 90/100: Loss: 1.0993\n",
      "Epoch 20/20, Batch 100/100: Loss: 0.9560\n",
      "Epoch 20/20 - Average Training Loss: 1.0248\n",
      "Epoch 20/20 - Training F1-score: 0.5316\n",
      "Epoch 20/20 - Training Precision: 0.5681\n",
      "Epoch 20/20 - Training Recall: 0.5128\n",
      "Epoch 20/20 - Validation Loss: 1.0930\n",
      "Epoch 20/20 - Validation F1-score: 0.4197\n",
      "Epoch 20/20 - Validation Precision: 0.5322\n",
      "Epoch 20/20 - Validation Recall: 0.4012\n"
     ]
    }
   ],
   "source": [
    "# 消融实验：只使用图像信息\n",
    "\n",
    "best_val_f1 = 0.0  \n",
    "best_train_f1 = 0.0  \n",
    "\n",
    "for epoch in range(args['epochs']):\n",
    "    print(f\"Starting Epoch {epoch+1}/{args['epochs']}...\")\n",
    "    \n",
    "    # 训练\n",
    "    only_image_model.train()\n",
    "    running_loss = 0.0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for batch_idx, batch in enumerate(train_loader):\n",
    "        text_inputs, attention_masks, img_inputs, labels = batch\n",
    "        \n",
    "        text_inputs = text_inputs.to(device)\n",
    "        attention_masks = attention_masks.to(device)\n",
    "        img_inputs = img_inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = only_image_model(img_inputs, text_inputs, attention_masks)  \n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        all_train_labels.extend(labels.cpu().numpy())\n",
    "        all_train_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        if (batch_idx + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{args['epochs']}, Batch {batch_idx+1}/{len(train_loader)}: \"\n",
    "                  f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Average Training Loss: {running_loss / len(train_loader):.4f}\")\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')  \n",
    "    train_precision = precision_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    train_recall = recall_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training F1-score: {train_f1:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training Precision: {train_precision:.4f}\")\n",
    "    print(f\"Epoch {epoch+1}/{args['epochs']} - Training Recall: {train_recall:.4f}\")\n",
    "\n",
    "    # 验证\n",
    "    only_image_model.eval()\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            text_inputs, attention_masks, img_inputs, labels = batch\n",
    "            text_inputs = text_inputs.to(device)\n",
    "            attention_masks = attention_masks.to(device)\n",
    "            img_inputs = img_inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = only_image_model(img_inputs, text_inputs, attention_masks)  \n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            all_val_labels.extend(labels.cpu().numpy())\n",
    "            all_val_preds.extend(predicted.cpu().numpy())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Loss: {val_loss / len(val_loader):.4f}\")\n",
    "        val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted') \n",
    "        val_precision = precision_score(all_val_labels, all_val_preds, average='weighted')\n",
    "        val_recall = recall_score(all_val_labels, all_val_preds, average='weighted')\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation F1-score: {val_f1:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Precision: {val_precision:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{args['epochs']} - Validation Recall: {val_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5336e449-f803-4680-ab9c-dacd984383db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d0478-94e8-4780-98f1-294aa9293e7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
